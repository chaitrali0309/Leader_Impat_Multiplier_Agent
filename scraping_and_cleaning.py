# -*- coding: utf-8 -*-
"""Scraping_and_cleaning.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_NYNNukNEY7HgW7B24A8GsPv7ckVF_Ku
"""

!pip -q install pdfplumber tqdm

import requests
import pdfplumber
import json
import io
import time
from tqdm import tqdm
import re

HEADERS = {"User-Agent": "Mozilla/5.0"}

def clean_text(text):
    if not text:
        return None
    return re.sub(r"\s+", " ", text).strip()

with open("prs_tharoor_questions.json", "r", encoding="utf-8") as f:
    questions = json.load(f)

enriched_questions = []

for q in tqdm(questions):
    url = q.get("url")

    # FIXED CONDITION
    if not url or ".pdf" not in url.lower():
        continue

    enriched_entry = q.copy()

    try:
        response = requests.get(url, headers=HEADERS)
        pdf_file = io.BytesIO(response.content)

        full_text = ""

        with pdfplumber.open(pdf_file) as pdf:
            for page in pdf.pages:
                text = page.extract_text()
                if text:
                    full_text += text + "\n"

        full_text = clean_text(full_text)
        enriched_entry["full_page_text"] = full_text

        # Split Question / Answer
        if "ANSWER" in full_text.upper():
            parts = re.split(r"ANSWER", full_text, maxsplit=1, flags=re.IGNORECASE)
            enriched_entry["question_text"] = clean_text(parts[0])
            enriched_entry["answer_text"] = clean_text(parts[1])
            enriched_entry["answered"] = True
        else:
            enriched_entry["question_text"] = full_text
            enriched_entry["answer_text"] = None
            enriched_entry["answered"] = False

    except Exception as e:
        enriched_entry["full_page_text"] = None
        enriched_entry["question_text"] = None
        enriched_entry["answer_text"] = None
        enriched_entry["answered"] = False

    enriched_questions.append(enriched_entry)

    time.sleep(0.7)  # safer delay

with open("prs_tharoor_questions_enriched.json", "w", encoding="utf-8") as f:
    json.dump(enriched_questions, f, indent=2, ensure_ascii=False)

print("✅ PDF Enrichment Complete.")
print("Total enriched:", len(enriched_questions))

!pip -q install tqdm

import json
import re
from tqdm import tqdm

def clean_spacing(text):
    if not text:
        return None
    text = re.sub(r"\s+", " ", text)
    return text.strip()

def remove_headers(text):
    # Remove common header patterns
    patterns = [
        r"GOVERNMENT OF INDIA.*?QUESTION NO\.\s*\d+",
        r"LOK SABHA.*?QUESTION NO\.\s*\d+",
        r"UNSTARRED QUESTION.*?",
        r"STARRED QUESTION.*?"
    ]
    for p in patterns:
        text = re.sub(p, "", text, flags=re.IGNORECASE)
    return text

def split_question_answer(text):
    # Add an explicit check for None input
    if text is None:
        return None, None
    # Split at ANSWER keyword
    parts = re.split(r"\bANSWER\b", text, maxsplit=1, flags=re.IGNORECASE)
    if len(parts) == 2:
        return parts[0], parts[1]
    return text, None

def remove_annexure(text):
    # Remove annexure tables
    text = re.split(r"\bANNEXURE\b", text, flags=re.IGNORECASE)[0]
    return text

# Load enriched data
with open("prs_tharoor_questions_enriched.json", "r", encoding="utf-8") as f:
    questions = json.load(f)

cleaned_questions = []

for q in tqdm(questions):
    full_text = q.get("full_page_text")

    if not full_text:
        # If full_page_text is None or empty, create a cleaned entry with None for question/answer bodies
        cleaned_entry = {
            "type": "parliament_question",
            "politician": "Shashi Tharoor",
            "date": q.get("Date"),
            "title": q.get("Title"),
            "ministry": q.get("Ministry or Category"),
            "question_body": None,
            "answer_body": None,
            "status": "Not Answered",
            "source_url": q.get("url")
        }
        cleaned_questions.append(cleaned_entry)
        continue # Skip further processing for this entry

    full_text = remove_headers(full_text)
    full_text = remove_annexure(full_text)
    full_text = clean_spacing(full_text)

    question_body, answer_body = split_question_answer(full_text)

    cleaned_entry = {
        "type": "parliament_question",
        "politician": "Shashi Tharoor",
        "date": q.get("Date"),
        "title": q.get("Title"),
        "ministry": q.get("Ministry or Category"),
        "question_body": clean_spacing(question_body),
        "answer_body": clean_spacing(answer_body),
        "status": "Answered" if answer_body else "Not Answered",
        "source_url": q.get("url")
    }

    cleaned_questions.append(cleaned_entry)

with open("prs_tharoor_questions_cleaned.json", "w", encoding="utf-8") as f:
    json.dump(cleaned_questions, f, indent=2, ensure_ascii=False)

print("✅ Cleaning complete")
print("Total cleaned:", len(cleaned_questions))

import json
import re
from tqdm import tqdm

def clean_spacing(text):
    if not text:
        return None
    text = re.sub(r"\s+", " ", text)
    return text.strip()

def extract_question_body(text):
    if not text:
        return None
    match = re.search(r"(Will the Minister.*)", text, re.IGNORECASE)
    if match:
        return match.group(1)
    return text

def clean_answer(text):
    if not text:
        return None
    # Remove minister name header
    text = re.sub(r"THE MINISTER.*?\)", "", text, flags=re.IGNORECASE)
    text = re.sub(r"\*{3,}", "", text)
    return text.strip()

with open("prs_tharoor_questions_cleaned.json", "r", encoding="utf-8") as f:
    questions = json.load(f)

final_questions = []

for q in tqdm(questions):

    question_body = clean_spacing(q.get("question_body"))
    answer_body = clean_spacing(q.get("answer_body"))

    question_body = extract_question_body(question_body)
    answer_body = clean_answer(answer_body)

    final_entry = q.copy()
    final_entry["question_body"] = question_body
    final_entry["answer_body"] = answer_body

    final_questions.append(final_entry)

with open("prs_tharoor_questions_final.json", "w", encoding="utf-8") as f:
    json.dump(final_questions, f, indent=2, ensure_ascii=False)

print("✅ Final cleaning complete.")
print("Total:", len(final_questions))

from google.colab import files
files.download("prs_tharoor_questions_final.json")